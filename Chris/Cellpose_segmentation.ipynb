{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fae8b4f-6aa6-4125-a72a-6bc2e087129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \twin32 \n",
      "python version: \t3.12.10 \n",
      "torch version:  \t2.8.0+cu126! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# IMPORTS\n",
    "# -------------------------------\n",
    "#multi image cellpose \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.measure import regionprops\n",
    "from cellpose import models, plot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c458ce66-d5f8-4877-a5a0-c29273c408eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labadmin\\Documents\\BZ-X800\\Chris\\Psychatg02_07112025\\S+B+_w1\n",
      "C:\\Users\\labadmin\\Documents\\BZ-X800\\Chris\\Psychatg02_07112025\\B+_w1\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1️⃣ PARAMETERS\n",
    "# -------------------------------\n",
    "image_folder = Path(\"C:/Users/labadmin/Documents/BZ-X800/Chris/Psychatg02_07112025\")  # folder with your images\n",
    "# save_folder = Path(\"C:/Users/labadmin/Documents/BZ-X800/Chris/Psychatg02_07112025/cellpose\")\n",
    "# save_folder.mkdir(exist_ok=True)\n",
    "\n",
    "condition1 = 'S+B+'\n",
    "condition2 = 'S-B+'\n",
    "\n",
    "condition1_folder = image_folder / \"S+B+_w1\"\n",
    "condition2_folder = image_folder / \"B+_w1\"\n",
    "\n",
    "print(condition1_folder)\n",
    "print(condition2_folder)\n",
    "\n",
    "#try to add parameters that will be used later in the code\n",
    "# search_only = ch2.tif or ch1.tif  \n",
    "# diameter = 30                # approx. size of cells\n",
    "# flow_threshold = 0.4\n",
    "# cellprob_threshold = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac1547f-80aa-4fc8-878a-da263865a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2️⃣ LOAD IMAGES\n",
    "# -------------------------------\n",
    "condition1_files = natsorted(list(condition1_folder.glob(\"**/HM_*_CH2.tif\")))\n",
    "# condition1_images = [io.imread(str(f)) for f in all_files]          # read as arrays\n",
    "condition2_files = natsorted(list(condition2_folder.glob(\"**/HM_*_CH2.tif\")))\n",
    "\n",
    "# condition2_files\n",
    "#analyze_files = only ch2 and ch4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331e22d7-7513-4272-97ce-1e5e0474e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3️⃣ INIT CELLPOSE MODEL\n",
    "# -------------------------------\n",
    "model = models.CellposeModel(gpu=True)  # or path to a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8dff3e4-59d3-4c6d-b638-836c11beecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# INITIALIZATION (MUST BE RUN BEFORE THE FUNCTION IS CALLED)\n",
    "\n",
    "# Load model (if not already)\n",
    "model = models.CellposeModel(gpu=True)\n",
    "\n",
    "# Store all image arrays, mask arrays, and flow arrays globally\n",
    "all_images = []\n",
    "all_masks = []\n",
    "all_flows = []\n",
    "\n",
    "def run_cell_analysis(ch2_path, file_id):\n",
    "    \"\"\"\n",
    "    Performs Cellpose segmentation and feature extraction for a single image pair.\n",
    "    The data is appended to the global 'rows' list.\n",
    "    \"\"\"\n",
    "    print(f\"/n--- Analyzing file: {os.path.basename(ch2_path)} ---\")\n",
    "\n",
    "    # Declare the lists as global so we can modify them\n",
    "    global all_images \n",
    "    global all_masks \n",
    "    global all_flows\n",
    "    \n",
    "    rows = [] \n",
    "    # Assume ch2_path is the full path string (e.g., '.../HM_W001_P00001_CH2.tif')\n",
    "    ch4_path = ch2_path.replace(\"_CH2.tif\", \"_CH4.tif\")\n",
    "    # 1. Load Images (as 2D grayscale)\n",
    "    ch1_img = io.imread(ch2_path, as_gray=True)\n",
    "    ch4_img = io.imread(ch4_path, as_gray=True)\n",
    "\n",
    "    # 2. Run Cellpose (on the ch1/GFP channel)\n",
    "    masks, flows, styles = model.eval([ch1_img],\n",
    "                                      diameter=30,\n",
    "                                      flow_threshold=2,\n",
    "                                      cellprob_threshold=1)\n",
    "    current_mask = masks[0] \n",
    "    current_flow = flows[0]\n",
    "\n",
    "    all_images.append(ch1_img)\n",
    "    all_masks.append(current_mask)\n",
    "    all_flows.append(current_flow)\n",
    "    \n",
    "# 3. Measure Properties for BOTH channels using the SAME masks\n",
    "    props = regionprops(current_mask, intensity_image=ch1_img) # Use current_mask\n",
    "    ch4_props = regionprops(current_mask, intensity_image=ch4_img) # Use current_mask\n",
    "    \n",
    "    # Get File Name (for tracking)\n",
    "    file_name = os.path.splitext(os.path.basename(ch2_path))[0]\n",
    "\n",
    "    # 4. COMBINE DATA INTO ONE ROW PER CELL (The main fix)\n",
    "    # The 'props' and 'ch4_props' lists are guaranteed to be in the same order \n",
    "    # and correspond to the same labels, so we use zip().\n",
    "    for p_gfp, p_s647 in zip(props, ch4_props):\n",
    "        rows.append({\n",
    "            \"file\": file_name,\n",
    "            \"primary_id\": file_id,\n",
    "            \"cell_id\": p_gfp.label,\n",
    "            \"area_px\": p_gfp.area,\n",
    "            \"mean_gfp\": p_gfp.mean_intensity,\n",
    "            \"mean_s647\": p_s647.mean_intensity # Both intensities are now in one row\n",
    "        })\n",
    "    \n",
    "    #return the data as a dataframe\n",
    "    return pd.DataFrame(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af80de-e793-4e27-971d-27db4ef8aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n--- Analyzing file: HM_W001_P00001_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00002_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00003_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00004_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00005_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00006_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "df_condition1 now has 830 rows.\n",
      "/n--- Analyzing file: HM_W001_P00001_CH2.tif ---\n",
      "\n",
      "--- Analyzing file---\n",
      "/n--- Analyzing file: HM_W001_P00002_CH2.tif ---\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4️⃣ RUN SEGMENTATION\n",
    "# -------------------------------\n",
    "\n",
    "df_list_condition1 = [] # Initialize an empty list to store results\n",
    "file_id_counter = 1\n",
    "\n",
    "# Loop through Condition 1 files\n",
    "for f in condition1_files:\n",
    "    # 1. Call the function and CAPTURE the returned DataFrame\n",
    "    df_single_file = run_cell_analysis(str(f), file_id=file_id_counter)    # 2. Append the single-file DataFrame to the list\n",
    "    df_list_condition1.append(df_single_file)\n",
    "    # 3. INCREMENT the counter so the next file gets the next ID\n",
    "    file_id_counter += 1    \n",
    "    print(f\"\\n--- Analyzing file---\")\n",
    "\n",
    "# 3. Combine all DataFrames into one final DataFrame\n",
    "df_condition1 = pd.concat(df_list_condition1, ignore_index=True)\n",
    "\n",
    "print(f\"df_condition1 now has {len(df_condition1)} rows.\")\n",
    "\n",
    "df_list_condition2 = []\n",
    "for f in condition2_files:\n",
    "    df_single_file = run_cell_analysis(str(f), file_id=file_id_counter)    \n",
    "    df_list_condition2.append(df_single_file)\n",
    "    print(f\"\\n--- Analyzing file---\")\n",
    "    file_id_counter += 1\n",
    "\n",
    "df_condition2 = pd.concat(df_list_condition2, ignore_index=True)\n",
    "print(f\"df_condition2 now has {len(df_condition2)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13ffde-e695-4f3c-aa49-1eee749817f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740acd43-e214-48d7-af90-46358cf932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the S+ and S-\n",
    "df_condition1['Condition'] = condition1\n",
    "df_condition2['Condition'] = condition2\n",
    "\n",
    "# Combine the two DataFrames\n",
    "df_combined = pd.concat([df_condition1, df_condition2], ignore_index=True)\n",
    "df_combined['ratio_s647_gfp'] = df_combined['mean_s647'] / (df_combined['mean_gfp'] + 1e-9) #added 1e-9 to help with no gfp errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ed0d8-16fe-438f-8236-56435fe9cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b977193-d970-4509-afd3-492ca3f2deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_combined,\n",
    "    x='mean_gfp',\n",
    "    y='mean_s647',\n",
    "    hue='Condition',  # Use the new column to distinguish colors\n",
    "    s = 10,\n",
    "    alpha=0.7         # Set transparency for better visibility of overlapping points\n",
    ")\n",
    "\n",
    "plt.xlabel(\"GFP Intensity (Channel 2)\")\n",
    "plt.ylabel(\"CH4 Intensity\")\n",
    "plt.title(\"Correlation of GFP vs. CH4 Intensity per Cell\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ae8ba-6497-49e6-927f-548d18a2fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plot \n",
    "sns.violinplot(\n",
    "    data=df_combined,\n",
    "    x='Condition',\n",
    "    y='ratio_s647_gfp',\n",
    "    hue='Condition',  # ADDED: Assign x to hue as recommended\n",
    "    legend=False,     # ADDED: Hide the redundant legend\n",
    "    palette=['blue', 'gray'],\n",
    "    order=['S-B+', 'S+B+']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75628e5-3929-4329-9861-d00004b27d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a94bf-dc6e-4bcd-815c-105fe40c650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1417423-ce46-4947-840d-5139587acf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529394-f405-46e9-aae4-8b189b2871a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import plot\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'img' is your original image and 'masks' is the array of masks\n",
    "# The 'masks' array is one of the outputs from model.eval() or loaded from a '_seg.npy' file\n",
    "\n",
    "mask_RGB = plot.mask_overlay(img, masks, colors=np.array(dat['colors']))\n",
    "plt.imshow(mask_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228548ae-bd1c-4b0b-8f7d-8b5fa36e8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'img' is your original image and 'mask' is the 2D mask array\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap='gray') # Show the original image first\n",
    "\n",
    "# 1. Get the outlines\n",
    "outlines = utils.outlines_list(mask)\n",
    "\n",
    "# 2. Plot the outlines\n",
    "for outline in outlines:\n",
    "    # outline is a list of (y, x) coordinates for the boundary\n",
    "    plt.plot(outline[:, 1], outline[:, 0], color='red', linewidth=1) \n",
    "    \n",
    "plt.title(\"Outlines over Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13778b37-c1c4-4a9b-ba74-a00634ad1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5️⃣ PLOT EXAMPLES (image + mask + flow)\n",
    "# -------------------------------\n",
    "for i in range(min(3, len(images))):  # show first 3 images\n",
    "    img = images[i]\n",
    "    mask = all_masks[i]\n",
    "    flow = all_flows[i]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(img if img.ndim==2 else img[..., :3])\n",
    "    axes[0].set_title(\"Original image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Mask overlay\n",
    "    overlay = label2rgb(mask, image=img if img.ndim==2 else img[..., :3], bg_label=0, alpha=0.3)\n",
    "    axes[1].imshow(overlay)\n",
    "    axes[1].set_title(\"Mask overlay\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Flow visualization\n",
    "    flow_x, flow_y = flow[1][0], flow[1][1]\n",
    "    axes[2].imshow(img if img.ndim==2 else img[..., :3], cmap='gray')\n",
    "    step = max(1, flow_x.shape[0] // 40)\n",
    "    axes[2].quiver(np.arange(0, flow_x.shape[1], step),\n",
    "                   np.arange(0, flow_y.shape[0], step),\n",
    "                   flow_x[::step, ::step],\n",
    "                   flow_y[::step, ::step],\n",
    "                   color='red', scale=40)\n",
    "    axes[2].set_title(\"Flow field\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42e847-9ab3-4301-82ed-eba173b900f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which image/mask pair to display. \n",
    "# Index 0 is the first image, 1 is the second, etc.\n",
    "# Check Cell In[53] to see how many files were processed.\n",
    "\n",
    "# --- CHANGE THIS INDEX TO PLOT A DIFFERENT IMAGE ---\n",
    "image_index = 0  # To plot the *first* image processed (HM_W001_P00001_CH2.tif)\n",
    "\n",
    "# 1. Assign the variables\n",
    "img = all_images[image_index]\n",
    "mask = all_masks[image_index]\n",
    "\n",
    "# 2. Print the shape to confirm data is loaded\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Mask shape: {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60f937-5e94-4e50-8200-b4ae130eff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f5dd6-51d8-4cfa-88b2-83ded51ab9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9a91b-8667-4872-a169-1689930bed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Cell In[51] - The outline plotting code)\n",
    "from cellpose import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'img' is your original image and 'mask' is the 2D mask array\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img) # Show the original image first\n",
    "\n",
    "# 1. Get the outlines\n",
    "outlines = utils.outlines_list(mask)\n",
    "\n",
    "# 2. Plot the outlines\n",
    "for outline in outlines:\n",
    "    # outline is a list of (y, x) coordinates for the boundary\n",
    "    plt.plot(outline[:, 1], outline[:, 0], color='red', linewidth=1) \n",
    "    \n",
    "plt.title(\"Outlines over Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a559653-3d65-43ad-b180-668a1451519b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0321d-2015-4c0b-a2bb-b289b48e5e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9307d1d-4dc4-40e3-b5eb-300ff715bc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250fdb4-8642-4958-bdcd-496f094092b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14228659-9ad6-4e54-92aa-6c4e6c0a653d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535380e-b7b3-4bf3-96d1-3fd4ff9e0bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477e50c-9526-47ed-8e13-572bc1eb7b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
