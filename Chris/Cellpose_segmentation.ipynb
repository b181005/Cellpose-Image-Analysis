{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc6e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: natsort in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (8.4.0)\n",
      "Requirement already satisfied: cellpose in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (4.0.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from scikit-image) (1.16.3)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from scikit-image) (3.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from scikit-image) (2025.10.16)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (0.24.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (4.12.0.88)\n",
      "Requirement already satisfied: fastremap in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (1.17.7)\n",
      "Requirement already satisfied: imagecodecs in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (2025.11.11)\n",
      "Requirement already satisfied: roifile in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (2025.5.10)\n",
      "Requirement already satisfied: fill-voids in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (2.1.1)\n",
      "Requirement already satisfied: segment_anything in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from cellpose) (1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from torch>=1.6->cellpose) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6->cellpose) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from jinja2->torch>=1.6->cellpose) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\b1810\\documents\\github\\cellpose-image-analysis\\.venv\\lib\\site-packages (from tqdm->cellpose) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install packages, only needed for first time use \n",
    "%pip install numpy matplotlib scikit-image pandas seaborn natsort cellpose\n",
    "# activate env \n",
    "# .\\cellpose_env\\Scripts\\Activate.ps1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fae8b4f-6aa6-4125-a72a-6bc2e087129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# IMPORTS\n",
    "# -------------------------------\n",
    "#multi image cellpose \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.measure import regionprops\n",
    "from cellpose import models, io, plot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c458ce66-d5f8-4877-a5a0-c29273c408eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labadmin\\Documents\\BZ-X800\\Chris\\Psychatg02_07112025\\S+B+_w1\n",
      "C:\\Users\\labadmin\\Documents\\BZ-X800\\Chris\\Psychatg02_07112025\\B+_w1\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1️⃣ PARAMETERS\n",
    "# -------------------------------\n",
    "image_folder = Path(\"C:/Users/labadmin/Documents/BZ-X800/Chris/Psychatg02_07112025\")  # folder with your images\n",
    "# save_folder = Path(\"C:/Users/labadmin/Documents/BZ-X800/Chris/Psychatg02_07112025/cellpose\")\n",
    "# save_folder.mkdir(exist_ok=True)\n",
    "\n",
    "condition1 = 'S+B+'\n",
    "condition2 = 'S-B+'\n",
    "\n",
    "condition1_folder = image_folder / \"S+B+_w1\"\n",
    "condition2_folder = image_folder / \"B+_w1\"\n",
    "\n",
    "print(condition1_folder)\n",
    "print(condition2_folder)\n",
    "\n",
    "#try to add parameters that will be used later in the code\n",
    "# search_only = ch2.tif or ch1.tif  \n",
    "# diameter = 30                # approx. size of cells\n",
    "# flow_threshold = 0.4\n",
    "# cellprob_threshold = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac1547f-80aa-4fc8-878a-da263865a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2️⃣ LOAD IMAGES\n",
    "# -------------------------------\n",
    "condition1_files = natsorted(list(condition1_folder.glob(\"**/HM_*_CH2.tif\")))\n",
    "# condition1_images = [io.imread(str(f)) for f in all_files]          # read as arrays\n",
    "condition2_files = natsorted(list(condition2_folder.glob(\"**/HM_*_CH2.tif\")))\n",
    "\n",
    "# condition2_files\n",
    "#analyze_files = only ch2 and ch4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331e22d7-7513-4272-97ce-1e5e0474e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3️⃣ INIT CELLPOSE MODEL\n",
    "# -------------------------------\n",
    "model = models.CellposeModel(gpu=True)  # or path to a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8dff3e4-59d3-4c6d-b638-836c11beecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# INITIALIZATION (MUST BE RUN BEFORE THE FUNCTION IS CALLED)\n",
    "\n",
    "# Load model (if not already)\n",
    "model = models.CellposeModel(gpu=True)\n",
    "\n",
    "# Store all image arrays, mask arrays, and flow arrays globally\n",
    "all_images = []\n",
    "all_masks = []\n",
    "all_flows = []\n",
    "\n",
    "def run_cell_analysis(ch2_path, file_id):\n",
    "    \"\"\"\n",
    "    Performs Cellpose segmentation and feature extraction for a single image pair.\n",
    "    The data is appended to the global 'rows' list.\n",
    "    \"\"\"\n",
    "    print(f\"/n--- Analyzing file: {os.path.basename(ch2_path)} ---\")\n",
    "\n",
    "    # Declare the lists as global so we can modify them\n",
    "    global all_images \n",
    "    global all_masks \n",
    "    global all_flows\n",
    "    \n",
    "    rows = [] \n",
    "    # Assume ch2_path is the full path string (e.g., '.../HM_W001_P00001_CH2.tif')\n",
    "    ch4_path = ch2_path.replace(\"_CH2.tif\", \"_CH4.tif\")\n",
    "    # 1. Load Images (as 2D grayscale)\n",
    "    ch1_img = io.imread(ch2_path, as_gray=True)\n",
    "    ch4_img = io.imread(ch4_path, as_gray=True)\n",
    "\n",
    "    # 2. Run Cellpose (on the ch1/GFP channel)\n",
    "    masks, flows, styles = model.eval([ch1_img],\n",
    "                                      diameter=30,\n",
    "                                      flow_threshold=2,\n",
    "                                      cellprob_threshold=1)\n",
    "    current_mask = masks[0] \n",
    "    current_flow = flows[0]\n",
    "\n",
    "    all_images.append(ch1_img)\n",
    "    all_masks.append(current_mask)\n",
    "    all_flows.append(current_flow)\n",
    "    \n",
    "# 3. Measure Properties for BOTH channels using the SAME masks\n",
    "    props = regionprops(current_mask, intensity_image=ch1_img) # Use current_mask\n",
    "    ch4_props = regionprops(current_mask, intensity_image=ch4_img) # Use current_mask\n",
    "    \n",
    "    # Get File Name (for tracking)\n",
    "    file_name = os.path.splitext(os.path.basename(ch2_path))[0]\n",
    "\n",
    "    # 4. COMBINE DATA INTO ONE ROW PER CELL (The main fix)\n",
    "    # The 'props' and 'ch4_props' lists are guaranteed to be in the same order \n",
    "    # and correspond to the same labels, so we use zip().\n",
    "    for p_gfp, p_s647 in zip(props, ch4_props):\n",
    "        rows.append({\n",
    "            \"file\": file_name,\n",
    "            \"primary_id\": file_id,\n",
    "            \"cell_id\": p_gfp.label,\n",
    "            \"area_px\": p_gfp.area,\n",
    "            \"mean_gfp\": p_gfp.mean_intensity,\n",
    "            \"mean_s647\": p_s647.mean_intensity # Both intensities are now in one row\n",
    "        })\n",
    "    \n",
    "    #return the data as a dataframe\n",
    "    return pd.DataFrame(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69af80de-e793-4e27-971d-27db4ef8aad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Analyzing file---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 3. Combine all DataFrames into one final DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df_condition1 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list_condition1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdf_condition1 now has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_condition1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m df_list_condition2 = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\b1810\\Documents\\GitHub\\Cellpose-Image-Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\b1810\\Documents\\GitHub\\Cellpose-Image-Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\b1810\\Documents\\GitHub\\Cellpose-Image-Analysis\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    504\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo objects to concatenate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    510\u001b[39m     objs_list = \u001b[38;5;28mlist\u001b[39m(com.not_none(*objs_list))\n",
      "\u001b[31mValueError\u001b[39m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4️⃣ RUN SEGMENTATION\n",
    "# -------------------------------\n",
    "\n",
    "df_list_condition1 = [] # Initialize an empty list to store results\n",
    "file_id_counter = 1\n",
    "\n",
    "# Loop through Condition 1 files\n",
    "for f in condition1_files:\n",
    "    # 1. Call the function and CAPTURE the returned DataFrame\n",
    "    df_single_file = run_cell_analysis(str(f), file_id=file_id_counter)    # 2. Append the single-file DataFrame to the list\n",
    "    df_list_condition1.append(df_single_file)\n",
    "    # 3. INCREMENT the counter so the next file gets the next ID\n",
    "    file_id_counter += 1    \n",
    "    print(f\"\\n--- Analyzing file---\")\n",
    "\n",
    "# 3. Combine all DataFrames into one final DataFrame\n",
    "df_condition1 = pd.concat(df_list_condition1, ignore_index=True)\n",
    "\n",
    "print(f\"df_condition1 now has {len(df_condition1)} rows.\")\n",
    "\n",
    "df_list_condition2 = []\n",
    "for f in condition2_files:\n",
    "    df_single_file = run_cell_analysis(str(f), file_id=file_id_counter)    \n",
    "    df_list_condition2.append(df_single_file)\n",
    "    print(f\"\\n--- Analyzing file---\")\n",
    "    file_id_counter += 1\n",
    "\n",
    "df_condition2 = pd.concat(df_list_condition2, ignore_index=True)\n",
    "print(f\"df_condition2 now has {len(df_condition2)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13ffde-e695-4f3c-aa49-1eee749817f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740acd43-e214-48d7-af90-46358cf932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the S+ and S-\n",
    "df_condition1['Condition'] = condition1\n",
    "df_condition2['Condition'] = condition2\n",
    "\n",
    "# Combine the two DataFrames\n",
    "df_combined = pd.concat([df_condition1, df_condition2], ignore_index=True)\n",
    "df_combined['ratio_s647_gfp'] = df_combined['mean_s647'] / (df_combined['mean_gfp'] + 1e-9) #added 1e-9 to help with no gfp errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ed0d8-16fe-438f-8236-56435fe9cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106feb6-641a-45af-9748-8b9891cd1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_num = 0\n",
    "# temp = df_combined['primary_id'].iloc[0]\n",
    "# total_num = 0\n",
    "# index = 0\n",
    "# average= []\n",
    "\n",
    "# for value in df_combined['primary_id']:\n",
    "#     if (temp == value):\n",
    "#        # print (\"here\")\n",
    "#         sum_num = sum_num + df_combined['ratio_s647_gfp'].iloc[index]\n",
    "#         #print (sum_num, \"and\", total_num)\n",
    "#         total_num = total_num + 1\n",
    "#         temp=value\n",
    "#         index = index + 1\n",
    "#     else:\n",
    "#         average.append(sum_num/total_num)\n",
    "#       #  print (\"here\")\n",
    "#         sum_num = 0\n",
    "#         total_num = 0\n",
    "#         temp=value\n",
    "#         index = index + 1\n",
    "# average.append(sum_num/total_num)\n",
    "# print (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd15f2-96c0-41cf-b2fd-1151a0e65b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg = df_combined.loc[(df_combined['primary_id'] == 1) & (df_combined['Condition'] == 'S+B+'), 'ratio_s647_gfp'].mean()\n",
    "print (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b977193-d970-4509-afd3-492ca3f2deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_combined,\n",
    "    x='mean_gfp',\n",
    "    y='mean_s647',\n",
    "    hue='Condition',  # Use the new column to distinguish colors\n",
    "    s = 10,\n",
    "    alpha=0.7         # Set transparency for better visibility of overlapping points\n",
    ")\n",
    "\n",
    "plt.xlabel(\"GFP Intensity (Channel 2)\")\n",
    "plt.ylabel(\"CH4 Intensity\")\n",
    "plt.title(\"Correlation of GFP vs. CH4 Intensity per Cell\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ae8ba-6497-49e6-927f-548d18a2fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plot \n",
    "sns.violinplot(\n",
    "    data=df_combined,\n",
    "    x='Condition',\n",
    "    y='ratio_s647_gfp',\n",
    "    hue='Condition',  # ADDED: Assign x to hue as recommended\n",
    "    legend=False,     # ADDED: Hide the redundant legend\n",
    "    palette=['blue', 'gray'],\n",
    "    order=['S-B+', 'S+B+']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75628e5-3929-4329-9861-d00004b27d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a94bf-dc6e-4bcd-815c-105fe40c650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1417423-ce46-4947-840d-5139587acf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529394-f405-46e9-aae4-8b189b2871a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming 'img' is your original image and 'masks' is the array of masks\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# The 'masks' array is one of the outputs from model.eval() or loaded from a '_seg.npy' file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m mask_RGB = plot.mask_overlay(\u001b[43mimg\u001b[49m, masks, colors=np.array(dat[\u001b[33m'\u001b[39m\u001b[33mcolors\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m      8\u001b[39m plt.imshow(mask_RGB)\n\u001b[32m      9\u001b[39m plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "from cellpose import plot\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'img' is your original image and 'masks' is the array of masks\n",
    "# The 'masks' array is one of the outputs from model.eval() or loaded from a '_seg.npy' file\n",
    "\n",
    "mask_RGB = plot.mask_overlay(img, masks, colors=np.array(dat['colors']))\n",
    "plt.imshow(mask_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228548ae-bd1c-4b0b-8f7d-8b5fa36e8b31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming 'img' is your original image and 'mask' is the 2D mask array\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m plt.imshow(\u001b[43mimg\u001b[49m, cmap=\u001b[33m'\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m# Show the original image first\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. Get the outlines\u001b[39;00m\n\u001b[32m      9\u001b[39m outlines = utils.outlines_list(mask)\n",
      "\u001b[31mNameError\u001b[39m: name 'img' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cellpose import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'img' is your original image and 'mask' is the 2D mask array\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap='gray') # Show the original image first\n",
    "\n",
    "# 1. Get the outlines\n",
    "outlines = utils.outlines_list(mask)\n",
    "\n",
    "# 2. Plot the outlines\n",
    "for outline in outlines:\n",
    "    # outline is a list of (y, x) coordinates for the boundary\n",
    "    plt.plot(outline[:, 1], outline[:, 0], color='red', linewidth=1) \n",
    "    \n",
    "plt.title(\"Outlines over Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13778b37-c1c4-4a9b-ba74-a00634ad1241",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 5️⃣ PLOT EXAMPLES (image + mask + flow)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[32m3\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mimages\u001b[49m))):  \u001b[38;5;66;03m# show first 3 images\u001b[39;00m\n\u001b[32m      5\u001b[39m     img = images[i]\n\u001b[32m      6\u001b[39m     mask = all_masks[i]\n",
      "\u001b[31mNameError\u001b[39m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5️⃣ PLOT EXAMPLES (image + mask + flow)\n",
    "# -------------------------------\n",
    "for i in range(min(3, len(images))):  # show first 3 images\n",
    "    img = images[i]\n",
    "    mask = all_masks[i]\n",
    "    flow = all_flows[i]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(img if img.ndim==2 else img[..., :3])\n",
    "    axes[0].set_title(\"Original image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Mask overlay\n",
    "    overlay = label2rgb(mask, image=img if img.ndim==2 else img[..., :3], bg_label=0, alpha=0.3)\n",
    "    axes[1].imshow(overlay)\n",
    "    axes[1].set_title(\"Mask overlay\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Flow visualization\n",
    "    flow_x, flow_y = flow[1][0], flow[1][1]\n",
    "    axes[2].imshow(img if img.ndim==2 else img[..., :3], cmap='gray')\n",
    "    step = max(1, flow_x.shape[0] // 40)\n",
    "    axes[2].quiver(np.arange(0, flow_x.shape[1], step),\n",
    "                   np.arange(0, flow_y.shape[0], step),\n",
    "                   flow_x[::step, ::step],\n",
    "                   flow_y[::step, ::step],\n",
    "                   color='red', scale=40)\n",
    "    axes[2].set_title(\"Flow field\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42e847-9ab3-4301-82ed-eba173b900f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m image_index = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# To plot the *first* image processed (HM_W001_P00001_CH2.tif)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. Assign the variables\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m img = \u001b[43mall_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m mask = all_masks[image_index]\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 2. Print the shape to confirm data is loaded\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Select which image/mask pair to display. \n",
    "# Index 0 is the first image, 1 is the second, etc.\n",
    "# Check Cell In[53] to see how many files were processed.\n",
    "\n",
    "# --- CHANGE THIS INDEX TO PLOT A DIFFERENT IMAGE ---\n",
    "image_index = 0  # To plot the *first* image processed (HM_W001_P00001_CH2.tif)\n",
    "\n",
    "# 1. Assign the variables\n",
    "img = all_images[image_index]\n",
    "mask = all_masks[image_index]\n",
    "\n",
    "# 2. Print the shape to confirm data is loaded\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Mask shape: {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60f937-5e94-4e50-8200-b4ae130eff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f5dd6-51d8-4cfa-88b2-83ded51ab9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9a91b-8667-4872-a169-1689930bed19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Assuming 'img' is your original image and 'mask' is the 2D mask array\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m plt.imshow(\u001b[43mimg\u001b[49m) \u001b[38;5;66;03m# Show the original image first\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 1. Get the outlines\u001b[39;00m\n\u001b[32m     10\u001b[39m outlines = utils.outlines_list(mask)\n",
      "\u001b[31mNameError\u001b[39m: name 'img' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (Cell In[51] - The outline plotting code)\n",
    "from cellpose import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'img' is your original image and 'mask' is the 2D mask array\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img) # Show the original image first\n",
    "\n",
    "# 1. Get the outlines\n",
    "outlines = utils.outlines_list(mask)\n",
    "\n",
    "# 2. Plot the outlines\n",
    "for outline in outlines:\n",
    "    # outline is a list of (y, x) coordinates for the boundary\n",
    "    plt.plot(outline[:, 1], outline[:, 0], color='red', linewidth=1) \n",
    "    \n",
    "plt.title(\"Outlines over Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a559653-3d65-43ad-b180-668a1451519b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0321d-2015-4c0b-a2bb-b289b48e5e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9307d1d-4dc4-40e3-b5eb-300ff715bc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250fdb4-8642-4958-bdcd-496f094092b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14228659-9ad6-4e54-92aa-6c4e6c0a653d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535380e-b7b3-4bf3-96d1-3fd4ff9e0bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477e50c-9526-47ed-8e13-572bc1eb7b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
